# -*- coding: utf-8 -*-
"""SDSC 4107 project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i25_85w1iMzDIC1Rou5b7Ejpg8IHaMw1
"""

import yfinance as yf
import pandas as pd
import math
import numpy as np
from scipy import stats
import datetime as dt
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
import matplotlib.pyplot as plt
import cvxopt as opt
from cvxopt import matrix, solvers
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, r2_score

# Download S&P 500 data
data = yf.download('^GSPC', start='2000-01-01', end='2023-01-01')

# Calculate daily returns FIRST
data['Return'] = data['Close'].pct_change()
# Calculate realized volatility (30-day window)
data['Realized_Vol'] = data['Return'].rolling(30).std() * np.sqrt(252)

# Target: future 30-day volatility
data['Target'] = data['Realized_Vol'].shift(-30)

# Features
data['Lag1'] = data['Realized_Vol'].shift(1)
data['MA50'] = data['Close'].rolling(50).mean()

#Add Features
data['Lag2_Realized_Vol'] = data['Realized_Vol'].shift(2)
data['Volume'] = data['Volume']
data['MA_Volume_30'] = data['Volume'].rolling(30).mean()
data['Lag1_Squared_Return'] = (data['Return']**2).shift(1)
data['Lag2_Squared_Return'] = (data['Return']**2).shift(2)
data = data.dropna()
returns = data[['Return', 'Realized_Vol', 'Target']]
X = data[['Lag1', 'Lag2_Realized_Vol', 'MA50', 'Volume', 'MA_Volume_30', 'Lag1_Squared_Return', 'Lag2_Squared_Return']]

# Split data
train_size = int(len(data) * 0.8)
X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_test = data['Target'].iloc[:train_size], data['Target'].iloc[train_size:]

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

mmscaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = mmscaler.fit_transform(data[['Close']])

rf_model= RandomForestRegressor(
    n_estimators=100,
    max_depth=5,            # Limit tree depth
    min_samples_leaf=10,    # Force larger leaves
    random_state=42
)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test_scaled).flatten()

# Scale features
feature_scaler = StandardScaler()
X_train_scaled = feature_scaler.fit_transform(X_train)
X_test_scaled = feature_scaler.transform(X_test)

from tensorflow.keras.layers import Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau


# Neural Network Architecture - Simplified to prevent overfitting
target_scaler = MinMaxScaler()
y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))

nn_model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    BatchNormalization(),
    Dropout(0.2),
    Dense(16, activation='relu'),
    BatchNormalization(),
    Dropout(0.1),
    Dense(8, activation='relu'),
    BatchNormalization(),
    Dense(1, activation='linear')
])

# Use Adam optimizer with lower learning rate and stronger regularization
optimizer = Adam(learning_rate=0.0001, decay=1e-3)

# Compile with MSE loss for regression tasks and add MAE as a metric
nn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

# Enhanced callbacks with more patience and better monitoring
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6, verbose=1)
early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose=1)

# Train with more controlled parameters
history = nn_model.fit(
    X_train_scaled, y_train_scaled,
    epochs=300,
    batch_size=32,  # Smaller batch size for better generalization
    validation_split=0.2,
    callbacks=[early_stop, reduce_lr],
    shuffle=True,
    verbose=1
)

# Predict and inverse transform the predictions
nn_pred_scaled = nn_model.predict(X_test_scaled)
# Make sure we're comparing predictions in the same scale as the targets
nn_pred = target_scaler.inverse_transform(nn_pred_scaled).flatten()

# Ensure predictions are within a reasonable range
nn_pred = np.clip(nn_pred, 0, y_test.max() * 1.2)  # Clip to prevent extreme values

# Support Vector Machine
svm_model = SVR(kernel='linear', C=1.0)
svm_model.fit(X_train_scaled, y_train)
svm_pred = svm_model.predict(X_test_scaled)

# Evaluate models
from sklearn.metrics import mean_squared_error, r2_score

# Calculate MSE
rf_mse = mean_squared_error(y_test, rf_pred)
nn_mse = mean_squared_error(y_test, nn_pred)
svm_mse = mean_squared_error(y_test, svm_pred)

# Calculate RÂ²
rf_r2 = r2_score(y_test, rf_pred)
nn_r2 = r2_score(y_test, nn_pred)
svm_r2 = r2_score(y_test, svm_pred)

# Print results
print(f'Random Forest - MSE: {rf_mse:.4f}, RÂ²: {rf_r2:.4f}')
print(f'Neural Network - MSE: {nn_mse:.4f}, RÂ²: {nn_r2:.4f}')
print(f'SVM - MSE: {svm_mse:.4f}, RÂ²: {svm_r2:.4f}')

# Time series plot
plt.figure(figsize=(12, 6))
plt.plot(X_test.index, y_test, label='Actual Volatility', color='blue')
plt.plot(X_test.index, rf_pred, label='RF Predicted', color='orange')
plt.plot(X_test.index, nn_pred, label='NN Predicted', color='green')
plt.plot(X_test.index, svm_pred, label='SVM Predicted', color='red')
plt.title('Actual vs Predicted Realized Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility (Annualized)')
plt.legend()
plt.show()

# Scatter plots
fig, axes = plt.subplots(1, 3, figsize=(18, 6))
for ax, pred, title in zip(axes, [rf_pred, nn_pred, svm_pred], ['Random Forest', 'Neural Network', 'SVM']):
    ax.scatter(y_test, pred, alpha=0.5)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    ax.set_title(f'{title} - Actual vs Predicted')
    ax.set_xlabel('Actual Volatility')
    ax.set_ylabel('Predicted Volatility')
plt.show()# Scatter plots
fig, axes = plt.subplots(1, 3, figsize=(18, 6))
for ax, pred, title in zip(axes, [rf_pred, nn_pred, svm_pred], ['Random Forest', 'Neural Network', 'SVM']):
    ax.scatter(y_test, pred, alpha=0.5)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    ax.set_title(f'{title} - Actual vs Predicted')
    ax.set_xlabel('Actual Volatility')
    ax.set_ylabel('Predicted Volatility')
plt.show()

# Download S&P 500 data from 2000 to 2023
sp500 = yf.download('^GSPC', start='2000-01-01', end='2023-12-31')

# Calculate daily returns
returns = sp500['Close'].pct_change()
def create_tail_risk_features(returns, window=30):
    features = pd.DataFrame(index=returns.index)

    # Calculate features for each asset
    for col in returns.columns:
        # Skewness
        features[f'skew_{col}'] = returns[col].rolling(window).skew()

        # Kurtosis
        features[f'kurt_{col}'] = returns[col].rolling(window).kurt()

        # Value at Risk (VaR)
        features[f'var95_{col}'] = returns[col].rolling(window).quantile(0.05)

        # Expected Shortfall (ES)
        features[f'es_{col}'] = returns[col].rolling(window).apply(
            lambda x: x[x <= np.percentile(x, 5)].mean()
        )

    # Portfolio-wide features
    # Extreme value indicators
    threshold = returns.std() * 3
    features['extreme_events'] = (returns.abs() > threshold).sum(axis=1)

    # Cross-asset correlation
    if len(returns.columns) > 1:
        rolling_corr = returns.rolling(window).corr()
        features['avg_correlation'] = rolling_corr.groupby(level=0).mean().mean(axis=1)

    return features.dropna()

def build_tail_risk_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(input_shape,)),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def create_dynamic_rebalancing_triggers(vol_pred, tail_risk_pred, threshold=0.15):
    # Ensure tail_risk_pred is the right shape
    if len(tail_risk_pred.shape) > 1:
        tail_risk_pred = tail_risk_pred.reshape(-1)

    # Calculate average volatility across assets
    if isinstance(vol_pred, pd.DataFrame):
        vol_pred = vol_pred.mean(axis=1)

    # Combine volatility and tail risk signals
    combined_signal = (vol_pred + tail_risk_pred) / 2

    # Generate rebalancing triggers
    triggers = combined_signal > threshold
    return triggers

class DynamicRiskManager:
    def __init__(self, returns_data, rebalance_frequency=30):
        self.returns = returns_data
        self.rebalance_frequency = rebalance_frequency
        self.features = create_tail_risk_features(self.returns)
        self.tail_risk_model = build_tail_risk_model(self.features.shape[1])

    def fit(self):
        # Create binary labels for tail risk events
        threshold = self.returns.std() * 2
        tail_events = (self.returns.abs() > threshold).any(axis=1).astype(int)

        # Align tail_events with features index
        tail_events = tail_events.loc[self.features.index]

        # Train test split
        X_train, X_test, y_train, y_test = train_test_split(
            self.features, tail_events, test_size=0.2, shuffle=False
        )

        # Train tail risk model
        self.tail_risk_model.fit(
            X_train, y_train,
            epochs=50,
            batch_size=32,
            validation_split=0.2,
            verbose=0
        )

    def optimize_portfolio(self, returns, predicted_vol, predicted_tail_risk, risk_tolerance=0.2):
        n = len(returns.columns)

        # Calculate mean returns and covariance
        mu = np.array(returns.mean()) * 252
        sigma = np.array(returns.cov()) * 252

        # Ensure proper dimensions for adjustments
        if isinstance(predicted_vol, pd.Series):
            predicted_vol = predicted_vol.values
        predicted_vol = np.clip(predicted_vol, 0.1, 2.0)  # Limit extreme values

        # Create diagonal matrices for adjustments
        vol_adjustment = np.diag(predicted_vol)
        tail_risk_adjustment = predicted_tail_risk * np.eye(n)

        # Adjust covariance matrix
        adjusted_sigma = sigma * (1 + tail_risk_adjustment)

        # Convert to cvxopt matrices
        P = matrix(adjusted_sigma)
        q = matrix(np.zeros(n))

        # Constraints
        G = matrix(np.vstack((-np.eye(n), np.eye(n))))
        h = matrix(np.hstack((np.zeros(n), np.ones(n))))
        A = matrix(np.ones((1, n)))
        b = matrix(1.0)

        # Solve optimization problem
        solvers.options['show_progress'] = False
        sol = solvers.qp(P, q, G, h, A, b)

        return np.array(sol['x']).flatten()


    def generate_allocations(self):
        # Predict volatility and align with features
        vol_pred = self.returns.rolling(window=30).std() * np.sqrt(252)
        vol_pred = vol_pred.loc[self.features.index]  # Key alignment fix

        # Predict tail risk using features
        tail_risk_pred = self.tail_risk_model.predict(self.features)

        # Generate rebalancing triggers
        triggers = create_dynamic_rebalancing_triggers(vol_pred, tail_risk_pred)

        # Initialize allocations DataFrame
        allocations = pd.DataFrame(
            index=self.features.index,  # Use aligned index
            columns=self.returns.columns,
            data=np.nan
        )

        # Generate portfolio weights for triggered dates
        for date in triggers[triggers].index:
            lookback = self.returns.loc[:date].tail(252)
            weights = self.optimize_portfolio(
                lookback,
                vol_pred.loc[date],
                tail_risk_pred[self.features.index.get_loc(date)]
            )
            allocations.loc[date] = weights

        # Forward fill allocations
        allocations = allocations.ffill()

        return allocations


risk_manager = DynamicRiskManager(returns)
risk_manager.fit()
portfolio_allocations = risk_manager.generate_allocations()

# Evaluate the strategy
def evaluate_strategy(returns, allocations):
    # Calculate portfolio returns
    portfolio_returns = (returns * allocations).sum(axis=1)

    # Calculate performance metrics
    annual_return = portfolio_returns.mean() * 252
    annual_vol = portfolio_returns.std() * np.sqrt(252)
    sharpe_ratio = annual_return / annual_vol
    max_drawdown = (portfolio_returns.cumsum() - portfolio_returns.cumsum().expanding().max()).min()

    print(f"Annual Return: {annual_return:.2%}")
    print(f"Annual Volatility: {annual_vol:.2%}")
    print(f"Sharpe Ratio: {sharpe_ratio:.2f}")
    print(f"Maximum Drawdown: {max_drawdown:.2%}")

    # Plot cumulative returns
    cumulative_returns = (1 + portfolio_returns).cumprod()
    plt.figure(figsize=(12, 6))
    plt.plot(cumulative_returns)
    plt.title('Portfolio Cumulative Returns')
    plt.xlabel('Date')
    plt.ylabel('Cumulative Return')
    plt.grid(True)
    plt.show()

# Evaluate the strategy
evaluate_strategy(returns, portfolio_allocations)

import yfinance as yf
import matplotlib.pyplot as plt
import datetime as dt

# Download S&P 500 data from 2000 to 2023
sp500 = yf.download('^GSPC', start='2000-01-01', end='2023-12-31')

# Calculate daily returns
returns = sp500['Close'].pct_change()

# Calculate 30-day rolling standard deviation and annualize it
rolling_std = returns.rolling(window=30).std()
annualized_vol = rolling_std * (252 ** 0.5) * 100  # Annualized volatility in percentage

# Create figure and subplots with shared x-axis
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)

# Plot S&P 500 Adjusted Close on log scale
ax1.plot(sp500.index, sp500['Close'], label='S&P 500 Close')
ax1.set_yscale('log')
ax1.set_ylabel('Price (log scale)')

# Plot annualized volatility
ax2.plot(annualized_vol.index, annualized_vol, label='30-day Rolling Volatility (Annualized)', color='orange')
ax2.set_ylabel('Volatility (%)')
ax2.set_xlabel('Date')

# Define crisis periods as datetime objects
covid_start = dt.datetime(2017, 1, 1)
covid_end = dt.datetime(2021, 1, 1)
fed_hike_start = dt.datetime(2020, 1, 1)
fed_hike_end = dt.datetime(2023, 6, 1)

# Add shaded regions for crisis periods on both subplots
ax1.axvspan(covid_start, covid_end, color='red', alpha=0.3, label='COVID Period (2017-2021)')
ax1.axvspan(fed_hike_start, fed_hike_end, color='blue', alpha=0.3, label='Fed Rate Hike Period (2020-2023)')
ax2.axvspan(covid_start, covid_end, color='red', alpha=0.3)
ax2.axvspan(fed_hike_start, fed_hike_end, color='blue', alpha=0.3)

# Add legend to the first subplot (price plot)
ax1.legend()

# Set subplot titles
ax1.set_title('S&P 500 Adjusted Close')
ax2.set_title('30-day Rolling Volatility (Annualized)')

# Add a super title for the entire figure
fig.suptitle('S&P 500 and its Volatility with Highlighted Crisis Periods')

# Adjust layout to prevent overlap
plt.tight_layout()

# Display the plot
plt.show()

data = yf.download('^GSPC', start='2000-01-01', end='2023-01-01')
data['Return'] = data['Close'].pct_change()

# Drop NaN values
data.dropna(inplace=True)

# Parameters for Monte Carlo Simulation
num_simulations = 1000
holding_period = 252  # Assuming one year of holding
starting_price = data["Close"].iloc[-1].item()
daily_returns = data["Return"].values

# Store results
all_simulations = []

# Monte Carlo Simulation
for _ in range(num_simulations):
    simulated_prices = [starting_price]
    for _ in range(holding_period):
        simulated_return = np.random.choice(daily_returns)
        next_price = simulated_prices[-1] * (1 + simulated_return)
        simulated_prices.append(next_price)
    all_simulations.append(simulated_prices)

# Convert results to a DataFrame for analysis
simulations_df = pd.DataFrame(all_simulations).T

# Plotting the results
plt.figure(figsize=(14, 7))
plt.plot(simulations_df, color='blue', alpha=0.1)
plt.title('Monte Carlo Simulations of S&P 500 Prices')
plt.xlabel('Days')
plt.ylabel('Price')
plt.axhline(y=starting_price, color='r', linestyle='--', label='Starting Price')
plt.legend()
plt.show()

# Calculate the 5th, 50th, and 95th percentiles of the final prices
final_prices = simulations_df.iloc[-1]
percentiles = np.percentile(final_prices, [5, 50, 95])
print(f"5th Percentile: {percentiles[0]}")
print(f"50th Percentile (Median): {percentiles[1]}")
print(f"95th Percentile: {percentiles[2]}")

# Investment Strategy based on simulated returns
investment_threshold = percentiles[1]  # Example: Invest if the simulated price exceeds this threshold

# Output investment strategy
if simulations_df.iloc[-1].mean() > investment_threshold:
    print("Investment Recommended: Future prices exceed the median projected price.")
else:
    print("Hold: Future prices do not exceed the median projected price.")

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt

# Download S&P 500 data
data = yf.download('^GSPC', start='2000-01-01', end='2023-01-01')
data['Return'] = data['Close'].pct_change()
data.dropna(inplace=True)

# Monte Carlo Simulation Parameters
num_simulations = 1000
holding_period = 252  # 1 year (252 trading days)
starting_price = data["Close"].iloc[-1].item()
daily_returns = data["Return"].values

# Run Monte Carlo Simulation
all_simulations = []
for _ in range(num_simulations):
    simulated_prices = [starting_price]
    for _ in range(holding_period):
        simulated_return = np.random.choice(daily_returns)
        next_price = simulated_prices[-1] * (1 + simulated_return)
        simulated_prices.append(next_price)
    all_simulations.append(simulated_prices)

simulations_df = pd.DataFrame(all_simulations).T

# Calculate final prices after 1 year
final_prices = simulations_df.iloc[-1]

# Define investment decision criteria
benchmark_price = starting_price  # Compare against initial price (0% return)
# benchmark_price = starting_price * 1.05  # Uncomment for a 5% target return

# Calculate probability of investment being profitable
probability_invest = (final_prices > benchmark_price).mean() * 100
probability_hold = 100 - probability_invest

# Print results
print(f"Probability that investing is profitable: {probability_invest:.2f}%")
print(f"Probability that holding (or not investing) is better: {probability_hold:.2f}%")

# Visualize distribution of final prices
plt.figure(figsize=(10, 6))
plt.hist(final_prices, bins=50, edgecolor='k', alpha=0.7)
plt.axvline(x=benchmark_price, color='r', linestyle='--', label='Benchmark Price')
plt.title('Distribution of Simulated S&P 500 Prices After 1 Year')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.legend()
plt.show()

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping


data = yf.download('^GSPC', start='2000-01-01', end='2023-01-01')
close_prices = data['Close'].values.reshape(-1, 1)

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(close_prices)

def create_sequences(data, window_size):
    X, y = [], []
    for i in range(window_size, len(data)):
        X.append(data[i - window_size:i])
        y.append(data[i])
    return np.array(X), np.array(y)

window_size = 60
X, y = create_sequences(scaled_data, window_size)

# ðŸšª Train/Test split
split_ratio = 0.9
split_index = int(len(X) * split_ratio)
X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

model = Sequential([
    LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.2),
    LSTM(100, return_sequences=False),
    Dropout(0.2),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

es = EarlyStopping(patience=5, restore_best_weights=True)
model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test), callbacks=[es])

last_sequence = scaled_data[-window_size:]
predictions = []

for _ in range(30):
    input_seq = last_sequence.reshape(1, window_size, 1)
    pred = model.predict(input_seq, verbose=0)
    predictions.append(pred[0])
    last_sequence = np.append(last_sequence, pred, axis=0)[-window_size:]D


predicted_prices = scaler.inverse_transform(predictions)

last_actual_date = data.index[-1]
future_dates = pd.date_range(start=last_actual_date + pd.Timedelta(days=1), periods=30, freq='B')

plt.figure(figsize=(12, 6))
plt.plot(data.index[-100:], close_prices[-100:], label='Historical')
plt.plot(future_dates, predicted_prices, label='Forecast (30 days)', color='r')
plt.title('S&P 500 Prediction: Next 30 Days')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import mean_squared_error, r2_score
import math

y_test_pred_scaled = model.predict(X_test)


y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1))
y_test_true = scaler.inverse_transform(y_test.reshape(-1, 1))


mse = mean_squared_error(y_test_true, y_test_pred)
rmse = math.sqrt(mse)
r2 = r2_score(y_test_true, y_test_pred)

print(f" Mean Squared Error (MSE): {mse:.4f}")
print(f" Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f" RÂ² Score: {r2:.4f}")

data = yf.download('^IRX', start='2010-01-01', end='2023-01-01')
interest_rate = data[['Close']].rename(columns={'Close': 'Interest Rate'})

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_rates = scaler.fit_transform(interest_rate)

# Create a dataset for the LSTM
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        a = data[i:(i + time_step), 0]
        X.append(a)
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Set time_step
time_step = 60
X, y = create_dataset(scaled_rates, time_step)

# Reshape input to be [samples, time steps, features]
X = X.reshape(X.shape[0], X.shape[1], 1)

train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

#Define the LSTM model
class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=50, num_layers=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])  # Get the last time step for prediction
        return out

# Initialize the model, loss function, and optimizer
model = LSTMModel()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
num_epochs = 100
for epoch in range(num_epochs):
    model.train()

    optimizer.zero_grad()
    outputs = model(torch.FloatTensor(X_train))
    loss = criterion(outputs, torch.FloatTensor(y_train.reshape(-1, 1)))
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

#Make Predictions
model.eval()
with torch.no_grad():
    train_predict = model(torch.FloatTensor(X_train))
    test_predict = model(torch.FloatTensor(X_test))

# Inverse transform to get the original interest rates
train_predict = scaler.inverse_transform(train_predict.numpy())
test_predict = scaler.inverse_transform(test_predict.numpy())
y_train_inverse = scaler.inverse_transform(y_train.reshape(-1, 1))
y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))

# Prepare for future predictions
# To predict beyond the end of our dataset, we'll need the last 'time_step' data points
last_input = scaled_rates[-time_step:].reshape(1, time_step, 1)

future_predictions = []
for _ in range(24):  # Predicting for the next 24 months (2 years)
    with torch.no_grad():
        next_rate = model(torch.FloatTensor(last_input))
        future_predictions.append(next_rate.numpy()[0][0])
        # Update the input with the latest prediction
        last_input = np.append(last_input[:, 1:, :], next_rate.numpy().reshape(1, 1, 1), axis=1)

# Inverse transform the future predictions
future_rates = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))


plt.figure(figsize=(14, 5))

# Calculate the correct indices for plotting
train_start = time_step
train_end = train_size + time_step
test_start = train_end
test_end = test_start + len(y_test_inverse)

# Plot training data
plt.plot(interest_rate.index[train_start:train_end], y_train_inverse, label='Train Actual')
plt.plot(interest_rate.index[train_start:train_end], train_predict, label='Train Predict', color='g')

# Plot testing data
plt.plot(interest_rate.index[test_start:test_end], y_test_inverse, label='Test Actual')
plt.plot(interest_rate.index[test_start:test_end], test_predict, label='Test Predict', color='r')

# Create a date range for future predictions
future_dates = pd.date_range(start=interest_rate.index[-1] + pd.Timedelta(days=1), periods=len(future_rates), freq='M')
plt.plot(future_dates, future_rates, label='Future Predictions', color='orange')

plt.title('Interest Rate Prediction')
plt.xlabel('Date')
plt.ylabel('Interest Rate (%)')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def calculate_metrics(actual, predicted, set_name):
    mse = mean_squared_error(actual, predicted)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(actual, predicted)
    r2 = r2_score(actual, predicted)

    print(f"{set_name} Metrics:")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RÂ²: {r2:.4f}\n")
    return rmse, mae

# Calculate metrics
train_rmse, train_mae = calculate_metrics(y_train_inverse, train_predict, "Training")
test_rmse, test_mae = calculate_metrics(y_test_inverse, test_predict, "Testing")